\section{Experimental Results and Analysis}

Our experimental approach follows a systematic three-phase progression: (1) evaluating baseline adaptation methods, (2) exploring hybrid approaches that build on the winning baseline, and (3) implementing selective routing. This section presents comprehensive results from all seven methods tested.

\begin{figure*}[t]
\centering
\includegraphics[width=0.95\textwidth]{results/figures/final_all_methods_comparison.png}
\caption{Complete method comparison showing all seven approaches tested. Unified LoRA (82.14\%) significantly outperforms all personalization attempts. Methods shown: Baseline (no adaptation), Unified LoRA, Per-Persona LoRA, Sparse MoE, Cluster LoRA, Hybrid LoRA, Weighted Merge, and Selective Routing.}
\label{fig:all_methods}
\end{figure*}

\subsection{Overview of Results}

Figure~\ref{fig:all_methods} presents the complete comparison of all seven methods. The key finding is unambiguous: \textbf{unified LoRA achieves 82.14\% embedding similarity, outperforming all six alternative approaches}. The performance ranking is:

\begin{enumerate}
\item \textbf{Selective Routing}: 82.99\% (+1.03\% vs unified, high complexity)
\item \textbf{Unified LoRA}: 82.14\% (baseline, winner for single model)
\item \textbf{Hybrid LoRA}: 75.91\% (-7.6\%)
\item \textbf{Cluster LoRA}: 74.14\% (-9.7\%)
\item \textbf{Per-Persona LoRA}: 68.28\% (-13.9\%)
\item \textbf{Weighted Merge}: 67.00\% (-18.4\%)
\item \textbf{Sparse MoE}: 66.38\% (-15.8\%)
\item \textbf{Baseline (No Adapt)}: 63.79\% (-18.4\%)
\end{enumerate}

This counterintuitive result—that simple unified training beats sophisticated personalization—demonstrates a fundamental principle: \textit{for small models with limited per-user data, data quantity dominates algorithmic sophistication}.

\subsection{Phase 1: Baseline Adaptation Attempts}

\begin{figure*}[h]
\centering
\includegraphics[width=0.95\textwidth]{results/figures/final_three_phases.png}
\caption{Three-phase experimental progression. \textbf{Phase 1}: Unified LoRA wins among baseline methods. \textbf{Phase 2}: Hybrid approaches still underperform unified. \textbf{Phase 3}: Selective routing provides minimal improvement (+1.03\%), with 77.5\% of personas preferring the unified model.}
\label{fig:three_phases}
\end{figure*}

\subsubsection{No Adaptation (Baseline)}

The pre-trained Qwen 0.5B Instruct model without any fine-tuning achieved 63.79\% embedding similarity. This establishes the value of domain adaptation: the 18.35\% gap to unified training demonstrates that smart home knowledge is not adequately captured in general pre-training.

\subsubsection{Unified LoRA (WINNER)}

Training a single LoRA adapter on all 6,000 dialogues achieved 82.14\% embedding similarity—the best single-model result. Configuration:

\begin{verbatim}
Trainable params: 2.4M (0.48% of base)
Training data:    6,000 examples (all personas)
Training time:    2 GPU hours
Rank: 8, Alpha: 16, Dropout: 0.05
Target modules:   q_proj, v_proj
\end{verbatim}

\textbf{Detailed metrics}:
\begin{itemize}
\item Embedding Similarity: 82.14\%
\item Device Precision: 93.80\%
\item Parameter F1: 89.58\%
\item Numerical Precision: 91.24\%
\item Variance: 0.0\% (perfectly consistent)
\end{itemize}

\textbf{Why unified wins}: The large training dataset (6,000 examples) prevents overfitting despite 2.4M trainable parameters. The model learns robust domain knowledge applicable across all personas rather than memorizing individual quirks.

\subsubsection{Per-Persona LoRA}

Training 200 individual LoRA adapters (one per persona, 20 dialogues each) achieved 68.28\% mean performance—13.9\% worse than unified. This represents severe overfitting: with only 20 training examples for 2.4M parameters (ratio of 120,000:1), the model memorizes training data rather than learning generalizable patterns.

\textbf{Distribution analysis}:
\begin{itemize}
\item Mean: 68.28\% $\pm$ 7.73\%
\item Range: 48.5\% - 94.1\% (45.6 point spread)
\item Training time: 200 GPU hours total
\end{itemize}

The high variance reveals instability: some personas achieved 94.1\% (lucky test examples similar to training), while others collapsed to 48.5\% (catastrophic overfitting). This 26× training time increase (200h vs 2h) yields substantially worse average performance.

\subsubsection{Sparse Mixture of Experts}

Merging K=5 most similar per-persona LoRAs using similarity-weighted averaging achieved 66.38\%—the worst performing method. This is even worse than the individual overfitted LoRAs (66.38\% vs 68.28\%), demonstrating that linear averaging of nonlinear function approximators is fundamentally destructive. The merged models exhibit no constructive interference; instead, averaging cancels out learned patterns.

\begin{table}[h]
\centering
\begin{tabular}{@{}lcccc@{}}
\toprule
Method & Similarity & vs Unified & Variance & Training Time \\ \midrule
\textbf{Unified LoRA} & \textbf{82.14\%} & \textbf{baseline} & \textbf{0.0\%} & \textbf{2h} \\
Per-Persona & 68.28\% & -13.9\% & 7.73\% & 200h \\
Sparse MoE & 66.38\% & -15.8\% & 8.74\% & 3.5min \\
Baseline & 63.79\% & -18.4\% & - & 0h \\ \bottomrule
\end{tabular}
\caption{Phase 1 results: Unified LoRA decisively wins}
\label{tab:phase1}
\end{table}

\subsection{Phase 2: Hybrid Approaches}

Given unified training's success, we explored whether personalization could be added \textit{on top of} the strong unified baseline rather than training from scratch. Three hybrid approaches were tested.

\begin{figure*}[h]
\centering
\includegraphics[width=0.95\textwidth]{results/figures/final_hybrid_comparison.png}
\caption{Hybrid method comparison. \textbf{Left}: Performance comparison showing all hybrid methods underperform unified. \textbf{Right}: Training efficiency (performance per GPU hour) showing unified's superior cost-benefit ratio.}
\label{fig:hybrid_comparison}
\end{figure*}

\subsubsection{Hybrid LoRA (Unified Base + Per-Persona Fine-tuning)}

\textbf{Approach}: Freeze the unified LoRA adapter and train a second, smaller per-persona LoRA on top.

\textbf{Results}:
\begin{itemize}
\item Score: 75.91\% (-7.6\% vs unified)
\item Variance: 6.89\% (high)
\item Range: 57.77\% - 93.16\%
\item Training: Two-stage (unified base + 200 persona adapters)
\item Time: 52 GPU hours total (2h unified + 50h persona)
\end{itemize}

\textbf{Analysis}: Best hybrid method, but still significantly worse than unified. Benefits from the strong 82.14\% foundation, but per-persona fine-tuning on just 20 examples causes overfitting. The trade-off is poor: 26× more training time for 7.6\% worse performance. High variance (6.89\%) indicates inconsistent results across personas.

\subsubsection{Cluster LoRA (Cluster-based Training)}

\textbf{Approach}: Group 200 personas into K=5 clusters using K-means on persona description embeddings, then train one LoRA per cluster.

\textbf{Clustering quality}:
\begin{itemize}
\item Silhouette score: 0.022 (scale: -1 to +1)
\item Interpretation: Very poor—personas don't form natural groups
\item Cluster sizes: 16-72 personas (480-2,160 training examples)
\end{itemize}

\textbf{Results} (only clusters 0 and 4 trained):
\begin{itemize}
\item Cluster 0 (16 personas, 480 examples): 72.65\% (-9.5\%)
\item Cluster 4 (72 personas, 2,160 examples): 74.14\% (-9.7\%)
\item Average: 74.14\% (using cluster 4 score)
\item Variance: 3.71\%
\item Training time: 2 GPU hours
\end{itemize}

\textbf{Analysis}: Despite careful hyperparameter tuning and training on 2,160 examples (36\% of total dataset), Cluster 4 underperforms unified by 9.7\%. Root causes:
\begin{enumerate}
\item Poor clustering quality (silhouette: 0.022)
\item Text similarity $\neq$ behavioral similarity
\item Insufficient data vs unified's 6,000 examples
\item Even 4.5× more data than smallest cluster can't overcome these issues
\end{enumerate}

\subsubsection{Weighted Merge (Smart Merging)}

\textbf{Approach}: Merge per-persona LoRAs using dual weighting by validation performance and centrality to cluster centroid.

\textbf{Merging formula}:
\begin{equation}
w_i = \text{val\_score}_i \times \text{centrality}_i, \quad W_{merged} = \sum_{i=1}^{K} w_i \cdot W_i
\end{equation}

\textbf{Results}:
\begin{itemize}
\item Score: 67.00\% (-18.4\% vs unified)
\item Variance: 20.11\% (very high)
\item Training time: 2 minutes (merging only)
\item Number merged: K=5 similar personas
\end{itemize}

\textbf{Analysis}: \textbf{Worst performing method}. Smart weighting strategy doesn't prevent destructive averaging. Linear combination of nonlinear weights fails systematically. Very high variance (20.11\%) shows extreme instability. Despite being fastest (2 min), performance is unacceptable—18.4\% worse than unified.

\begin{table}[h]
\centering
\begin{tabular}{@{}lccccc@{}}
\toprule
Method & Score & vs Unified & Variance & Time & Efficiency\textsuperscript{*} \\ \midrule
\textbf{Unified} & \textbf{82.14\%} & \textbf{0.0\%} & \textbf{0.0\%} & \textbf{2h} & \textbf{0.411} \\
Hybrid LoRA & 75.91\% & -7.6\% & 6.89\% & 52h & 0.015 \\
Cluster LoRA & 74.14\% & -9.7\% & 3.71\% & 2h & 0.371 \\
Weighted Merge & 67.00\% & -18.4\% & 20.11\% & 2min & 20.100 \\ \bottomrule
\end{tabular}
\caption{Phase 2 hybrid method comparison. \textsuperscript{*}Efficiency = Score / GPU Hours. Weighted Merge appears efficient but delivers poor absolute performance.}
\label{tab:phase2}
\end{table}

\textbf{Key insight from Phase 2}: All three hybrid strategies fail to beat unified. The best hybrid (Hybrid LoRA at 75.91\%) still loses by 7.6\%. Attempting to build personalization on top of unified either:
\begin{itemize}
\item Overfits on limited data (Hybrid LoRA)
\item Suffers from poor clustering (Cluster LoRA)
\item Destroys learned patterns through averaging (Weighted Merge)
\end{itemize}

\subsection{Phase 3: Selective Routing}

If no single personalized approach beats unified, can we identify \textit{which specific personas} benefit from personalization and route them accordingly?

\begin{figure*}[h]
\centering
\includegraphics[width=0.95\textwidth]{results/figures/final_routing_analysis.png}
\caption{Selective routing analysis. \textbf{Left}: Distribution of improvements showing most personas (77.5\%) perform best with unified model. \textbf{Right}: Summary statistics demonstrating that only a minority benefit from personalization.}
\label{fig:routing}
\end{figure*}

\subsubsection{Routing Strategy}

For each persona, evaluate validation performance using unified, per-persona, and hybrid models. Route each persona to their best-performing model based on a simple lookup table.

\subsubsection{Results}

\textbf{Overall performance}:
\begin{itemize}
\item Unified (all personas): 82.14\%
\item Selective routing: 82.99\%
\item Improvement: +0.85\% (+1.03\% relative)
\end{itemize}

\textbf{Routing decisions (200 personas)}:
\begin{itemize}
\item Unified: 155 personas (77.5\%)
\item Hybrid: 41 personas (20.5\%)
\item Personalized: 4 personas (2.0\%)
\end{itemize}

\textbf{Top improvements}:
\begin{itemize}
\item persona\_180: +11.99\% (personalized, 94.1\%)
\item persona\_091: +11.02\% (hybrid, 93.2\%)
\item persona\_026: +8.99\% (hybrid, 91.1\%)
\end{itemize}

\textbf{Analysis}: Selective routing achieves modest improvement (+1.03\%) by identifying the 22.5\% of personas that benefit from personalization. However, the vast majority (77.5\%) perform best with the simple unified model. The personas benefiting from personalization exhibit:
\begin{itemize}
\item Highly consistent device preferences (e.g., always 70\% brightness)
\item Distinctive speaking styles (very terse or very verbose)
\item Test examples matching training distribution (lucky overfitting)
\end{itemize}

\textbf{Cost-benefit analysis}:
\begin{itemize}
\item \textbf{Advantages}: Guaranteed $\geq$ unified performance, identifies minority benefiting from personalization
\item \textbf{Disadvantages}: Must train and store 200+ models, routing complexity, minimal improvement (+1.03\%), helps only 22.5\% of users
\end{itemize}

\subsection{Cross-Method Analysis}

\subsubsection{The Data Quantity Dominance Principle}

Across all experiments, performance scales with training data quantity:

\begin{table}[h]
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
Method & Training Examples & Embedding Sim & Rank \\ \midrule
\textbf{Unified LoRA} & \textbf{6,000} & \textbf{82.14\%} & \textbf{1} \\
Cluster 4 LoRA & 2,160 & 74.14\% & 2 \\
Cluster 0 LoRA & 480 & 72.65\% & 3 \\
Hybrid LoRA & 20 + frozen & 75.91\% & 2* \\
Per-Persona LoRA & 20 & 68.28\% & 4 \\
Weighted Merge & merged & 67.00\% & 5 \\ \bottomrule
\end{tabular}
\caption{Performance vs training data. *Hybrid benefits from frozen unified base. Clear pattern: more data correlates with better performance.}
\label{tab:data_scaling}
\end{table}

For small models (0.5B parameters) on specialized tasks:
\begin{equation}
\text{Performance} \propto \text{log}(\text{Training Examples})
\end{equation}

\textbf{Interpretation}: Data quantity dominates algorithmic sophistication. 6,000 unified examples beat 20-2,160 personalized examples across all methods.

\subsubsection{When Might Personalization Work?}

Based on our experimental failures, personalization would require:

\begin{enumerate}
\item \textbf{More data per persona}: 100+ examples (vs 20 in our study)
\item \textbf{Larger models}: 3B+ parameters (vs 0.5B) for dual objectives
\item \textbf{Better clustering}: Silhouette score $>$ 0.3 (vs 0.022)
\item \textbf{Highly personal tasks}: $>$50\% personality-dependent (vs $\sim$25\% for smart home)
\end{enumerate}

\textbf{Current status}: None of these conditions are met. Our dataset and task favor unified training.

\subsubsection{Task Complexity Breakdown}

Analysis of 6,000 dialogues reveals task distribution:

\begin{table}[h]
\centering
\begin{tabular}{@{}lcc@{}}
\toprule
Task Type & Proportion & Unified Accuracy \\ \midrule
Simple commands & 40\% & 89\% \\
Multi-device commands & 35\% & 78\% \\
Context-dependent & 15\% & 71\% \\
Personality-heavy & 10\% & 65\% \\ \bottomrule
\end{tabular}
\caption{Task complexity distribution. Unified model excels at 75\% of tasks (simple + multi-device), limiting personalization benefit.}
\label{tab:task_complexity}
\end{table}

\textbf{Insight}: Only 25\% of tasks (context-dependent + personality-heavy) potentially benefit from personalization. For 75\% of tasks, domain knowledge matters more than individual preferences. This explains why unified training succeeds: it optimizes for the majority use case.

\subsection{Summary of Results}

\begin{figure*}[t]
\centering
\includegraphics[width=\textwidth]{results/figures/final_complete_summary.png}
\caption{Complete experimental summary showing all results and key findings. Top: All seven methods compared. Middle: Phase progression and routing breakdown. Bottom: Key insights summary.}
\label{fig:complete_summary}
\end{figure*}

Figure~\ref{fig:complete_summary} provides a comprehensive summary. The experimental evidence is clear:

\begin{enumerate}
\item \textbf{Unified LoRA wins}: 82.14\% beats all personalization attempts (67-76\%)
\item \textbf{Data quantity dominates}: 6,000 examples $>$ sophisticated personalization on 20-2,160 examples
\item \textbf{Personalization helps minority}: Only 22.5\% of personas benefit (selective routing)
\item \textbf{Training efficiency matters}: Unified provides best performance/hour ratio
\item \textbf{Consistency is crucial}: Unified shows 0\% variance vs 4-20\% for personalized methods
\end{enumerate}

\textbf{Practical recommendation}: For this dataset and task, use Unified LoRA. It provides:
\begin{itemize}
\item Best single-model performance (82.14\%)
\item Simplest deployment (one model)
\item Fastest training (2 hours)
\item Most consistent results (0\% variance)
\item Lower engineering complexity
\end{itemize}

Personalization methods require substantial additional engineering (multiple models, routing logic, merge strategies) for minimal or negative return (-18\% to +1\%). The juice is not worth the squeeze.
